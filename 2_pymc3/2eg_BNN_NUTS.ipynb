{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: \n",
    "\n",
    "# https://alexioannides.com/2018/11/07/bayesian-regression-in-pymc3-using-mcmc-variational-inference/\n",
    "# https://docs.pymc.io/notebooks/bayesian_neural_network_advi.html\n",
    "\n",
    "# http://stronginference.com/pymc3-release.html\n",
    "# https://docs.pymc.io/notebooks/getting_started.html\n",
    "\n",
    "# https://towardsdatascience.com/hands-on-bayesian-statistics-with-python-pymc3-arviz-499db9a59501"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About NUTS [a self tuning form of HMC]\n",
    "http://stronginference.com/pymc3-release.html\n",
    "    \n",
    "Though the version 2 and version 3 models are superficially similar (by design), there are very different things happening underneath when sampleis called in either case. By default, the PyMC3 model will use a form of gradient-based MCMC sampling, a self-tuning form of Hamiltonian Monte Carlo, called NUTS. Gradient based methods serve to drastically improve the efficiency of MCMC, without the need for running long chains and dropping large portions of the chains due to lack of convergence. Rather than conditionally sampling each model parameter in turn, the NUTS algorithm walks in k-space (where k is the number of model parameters), simultaneously updating all the parameters as it leap-frogs through the parameter space. Models of moderate complexity and size that would normally require 50,000 to 100,000 iterations now typically require only 2000-3000.\n",
    "\n",
    "Unless specified otherwise, PyMC3 will assign the NUTS sampler to all the variables of the model. This happens here because our model contains only continuous random variables; NUTS will not work with discrete variables because it is impossible to obtain gradient information from them. Discrete variables are assigned the Metropolissampling algorithm (step method, in PyMC parlance). The next thing that happens is that the variables' initial values are assigned using Automatic Differentiation Variational Inference (ADVI). This is an approximate Bayesian inference algorithm that we have added to PyMC — more on that later. Though it can be used for inference in its own right, here we are using it merely to find good starting values for NUTS (in practice, this is important for getting NUTS to run well). Its an excessive step for small models like this, but it is the default behavior, designed to try and guarantee a good MCMC run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named 'mkl'\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import theano\n",
    "floatX = theano.config.floatX\n",
    "import pymc3 as pm\n",
    "import theano.tensor as T\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "sns.set_style('white')\n",
    "np.random.seed(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(94, 1) (94, 1)\n"
     ]
    }
   ],
   "source": [
    "# Building dataset\n",
    "\n",
    "data = np.loadtxt('motor.dat')\n",
    "\n",
    "X_data = data[:, 0][:, None]\n",
    "y_data = data[:, 1][:, None]\n",
    "\n",
    "print (np.shape(X_data),np.shape(y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(94, 1) (94, 1)\n"
     ]
    }
   ],
   "source": [
    "# Shuffling dataset\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_data_shuff,y_data_shuff = shuffle(X_data,y_data,random_state=23)\n",
    "print (np.shape(X_data_shuff),np.shape(y_data_shuff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 1) (75, 1)\n",
      "(19, 1) (19, 1)\n"
     ]
    }
   ],
   "source": [
    "# Splitting dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data_shuff, y_data_shuff, test_size=0.2, random_state=23)\n",
    "print (np.shape(X_train), np.shape(y_train))\n",
    "print (np.shape(X_test), np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building pymc model\n",
    "\n",
    "n_hidden = 10\n",
    "\n",
    "# Initialize random weights between each layer\n",
    "init_w_1 = np.random.randn(X_train.shape[1], n_hidden).astype(floatX)\n",
    "init_w_2 = np.random.randn(n_hidden, n_hidden).astype(floatX)\n",
    "init_w_out = np.random.randn(n_hidden,1).astype(floatX)\n",
    "\n",
    "init_b_1 = np.random.randn(n_hidden).astype(floatX)\n",
    "init_b_2 = np.random.randn(n_hidden).astype(floatX)\n",
    "init_b_out = np.random.randn(1).astype(floatX)\n",
    "\n",
    "\n",
    "def DNN(x_tensor, weights_in_1, bias_in_1, weights_1_2, bias_1_2, weights_2_out, bias_2_out):\n",
    "    act_1 = pm.math.tanh(pm.math.dot(x_tensor,weights_in_1)+bias_in_1)\n",
    "    act_2 = pm.math.tanh(pm.math.dot(act_1,weights_1_2)+bias_1_2)\n",
    "    act_out = pm.math.dot(act_2,weights_2_out)+bias_2_out\n",
    "    return act_out\n",
    "\n",
    "with pm.Model() as neural_network:\n",
    "    # Trick: Turning inputs and outputs into shared variables \n",
    "    # It's still the same thing, but we can later change the values of the shared variable\n",
    "    # (to switch in the test-data later) and pymc3 will just use the new data.\n",
    "    # Kind-of like a pointer we can redirect.\n",
    "    # For more info, see: http://deeplearning.net/software/theano/library/compile/shared.html\n",
    "    y_tensor = theano.shared(y_train)\n",
    "    x_tensor = theano.shared(X_train)\n",
    "\n",
    "    #PRIOR\n",
    "    # Weights and biases from input to hidden layer\n",
    "    weights_in_1 = pm.Normal('w_in_1', 0, sigma=1,\n",
    "                             shape=(X_train.shape[1], n_hidden),\n",
    "                             testval=init_w_1)\n",
    "    \n",
    "    bias_in_1 = pm.Normal('b_in_1', 0, sigma=1,\n",
    "                             shape=(n_hidden),\n",
    "                             testval=init_b_1)\n",
    "\n",
    "    # Weights and biases from 1st to 2nd layer\n",
    "    weights_1_2 = pm.Normal('w_1_2', 0, sigma=1,\n",
    "                            shape=(n_hidden, n_hidden),\n",
    "                            testval=init_w_2)\n",
    "  \n",
    "    bias_1_2 = pm.Normal('b_1_2', 0, sigma=1,\n",
    "                             shape=(n_hidden),\n",
    "                             testval=init_b_2)\n",
    "\n",
    "    # Weights and biases from hidden layer to output\n",
    "    weights_2_out = pm.Normal('w_2_out', 0, sigma=1,\n",
    "                              shape=(n_hidden,1),\n",
    "                              testval=init_w_out)\n",
    "\n",
    "    bias_2_out = pm.Normal('b_2_out', 0, sigma=1,\n",
    "                             shape=(1),\n",
    "                             testval=init_b_out)\n",
    "        \n",
    "    # Build neural-network using activation function\n",
    "    act_out = DNN(x_tensor, weights_in_1, bias_in_1, weights_1_2, bias_1_2, weights_2_out, bias_2_out)\n",
    "\n",
    "    # LIKELIHOOD\n",
    "    out = pm.Normal('out', mu=act_out, sigma=0.1, observed=y_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 94)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#checking prior draws\n",
    "\n",
    "with neural_network:\n",
    "    preds =[DNN(X_data, weights_in_1.random(), bias_in_1.random(), weights_1_2.random(), bias_1_2.random(), weights_2_out.random(), bias_2_out.random()).eval()\n",
    "     for _ in range(5)]\n",
    "    preds = np.asarray(preds)\n",
    "    outputs = preds.reshape(preds.shape[0],preds.shape[1])\n",
    "    print(np.shape(outputs))\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(y_data, 'ks', alpha=0.5, label='(x, y)') # full data (train+test)\n",
    "    ax.plot(outputs[0].T, 'r', lw=2, alpha=0.5, label='prior draws')\n",
    "    ax.plot(outputs[1:].T, 'r', lw=2, alpha=0.5)\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymc3.theanof import set_tt_rng, MRG_RandomStreams\n",
    "set_tt_rng(MRG_RandomStreams(42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n",
      "WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [b_2_out, w_2_out, b_1_2, w_1_2, b_in_1, w_in_1]\n",
      "Sampling 2 chains, 0 divergences:  12%|█▏        | 1432/12000 [00:07<00:57, 185.35draws/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Chain 0 failed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/sharmila/anaconda3/envs/py36/lib/python3.6/site-packages/pymc3/parallel_sampling.py\", line 110, in run\n    self._start_loop()\n  File \"/Users/sharmila/anaconda3/envs/py36/lib/python3.6/site-packages/pymc3/parallel_sampling.py\", line 160, in _start_loop\n    point, stats = self._compute_point()\n  File \"/Users/sharmila/anaconda3/envs/py36/lib/python3.6/site-packages/pymc3/parallel_sampling.py\", line 191, in _compute_point\n    point, stats = self._step_method.step(self._point)\n  File \"/Users/sharmila/anaconda3/envs/py36/lib/python3.6/site-packages/pymc3/step_methods/arraystep.py\", line 247, in step\n    apoint, stats = self.astep(array)\n  File \"/Users/sharmila/anaconda3/envs/py36/lib/python3.6/site-packages/pymc3/step_methods/hmc/base_hmc.py\", line 130, in astep\n    self.potential.raise_ok(self._logp_dlogp_func._ordering.vmap)\n  File \"/Users/sharmila/anaconda3/envs/py36/lib/python3.6/site-packages/pymc3/step_methods/hmc/quadpotential.py\", line 231, in raise_ok\n    raise ValueError('\\n'.join(errmsg))\nValueError: Mass matrix contains zeros on the diagonal. \nThe derivative of RV `b_1_2`.ravel()[3] is zero.\nThe derivative of RV `w_1_2`.ravel()[3] is zero.\nThe derivative of RV `w_1_2`.ravel()[10] is zero.\nThe derivative of RV `w_1_2`.ravel()[13] is zero.\nThe derivative of RV `w_1_2`.ravel()[18] is zero.\nThe derivative of RV `w_1_2`.ravel()[20] is zero.\nThe derivative of RV `b_in_1`.ravel()[0] is zero.\nThe derivative of RV `b_in_1`.ravel()[2] is zero.\nThe derivative of RV `b_in_1`.ravel()[3] is zero.\nThe derivative of RV `b_in_1`.ravel()[4] is zero.\nThe derivative of RV `w_in_1`.ravel()[0] is zero.\nThe derivative of RV `w_in_1`.ravel()[2] is zero.\nThe derivative of RV `w_in_1`.ravel()[3] is zero.\nThe derivative of RV `w_in_1`.ravel()[4] is zero.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;31mValueError\u001b[0m: Mass matrix contains zeros on the diagonal. \nThe derivative of RV `b_1_2`.ravel()[3] is zero.\nThe derivative of RV `w_1_2`.ravel()[3] is zero.\nThe derivative of RV `w_1_2`.ravel()[10] is zero.\nThe derivative of RV `w_1_2`.ravel()[13] is zero.\nThe derivative of RV `w_1_2`.ravel()[18] is zero.\nThe derivative of RV `w_1_2`.ravel()[20] is zero.\nThe derivative of RV `b_in_1`.ravel()[0] is zero.\nThe derivative of RV `b_in_1`.ravel()[2] is zero.\nThe derivative of RV `b_in_1`.ravel()[3] is zero.\nThe derivative of RV `b_in_1`.ravel()[4] is zero.\nThe derivative of RV `w_in_1`.ravel()[0] is zero.\nThe derivative of RV `w_in_1`.ravel()[2] is zero.\nThe derivative of RV `w_in_1`.ravel()[3] is zero.\nThe derivative of RV `w_in_1`.ravel()[4] is zero.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-dbca73828de0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Carrying out MCMC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mneural_network\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdraws\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraceplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/pymc3/sampling.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(draws, step, init, n_init, start, trace, chain_idx, chains, cores, tune, progressbar, model, random_seed, discard_tuned_samples, compute_convergence_checks, **kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0m_print_step_hierarchy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_mp_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msample_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPickleError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0m_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Could not pickle model, sampling singlethreaded.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/pymc3/sampling.py\u001b[0m in \u001b[0;36m_mp_sample\u001b[0;34m(draws, tune, step, chains, cores, chain, random_seed, start, progressbar, trace, model, **kwargs)\u001b[0m\n\u001b[1;32m   1057\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mdraw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m                     \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraces\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_sampler_stats\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/pymc3/parallel_sampling.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0mdraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProcessAdapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_draw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m             \u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_last\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_progress\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/pymc3/parallel_sampling.py\u001b[0m in \u001b[0;36mrecv_draw\u001b[0;34m(processes, timeout)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Chain %s failed.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mold_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"writing_done\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Chain 0 failed."
     ]
    }
   ],
   "source": [
    "# Carrying out MCMC\n",
    "with neural_network:\n",
    "    trace = pm.sample(draws=5000, tune=1000, cores=2)\n",
    "\n",
    "pm.traceplot(trace)\n",
    "pm.summary(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking posterior draws\n",
    "\n",
    "preds =[DNN(X_data, trace['w_in_1'][i], trace['b_in_1'][i], trace['w_1_2'][i], trace['b_1_2'][i], trace['w_2_out'][i], trace['b_2_out'][i]).eval()\n",
    " for i in range(5)]\n",
    "preds = np.asarray(preds)\n",
    "outputs = preds.reshape(preds.shape[0],preds.shape[1])\n",
    "print(np.shape(outputs))\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(y_data, 'ks', alpha=0.5, label='(x, y)') # full data (train+test)\n",
    "ax.plot(outputs[0].T, 'r', lw=2, alpha=0.5, label='posterior draws')\n",
    "ax.plot(outputs[1:].T, 'r', lw=2, alpha=0.5)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing on whole data for now instead of test data\n",
    "y_tensor.set_value(y_data)\n",
    "x_tensor.set_value(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_preds = pm.sample_posterior_predictive(trace, 1000, neural_network)\n",
    "mean_prediction = np.mean(posterior_preds['out'], axis=0)\n",
    "stddev_prediction = np.std(posterior_preds['out'], axis=0)\n",
    "print (posterior_preds['out'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data = pd.DataFrame(\n",
    "    {'MCMC': mean_prediction.flatten(), \n",
    "     'actual': y_data.flatten(),\n",
    "     'error_MCMC': ( mean_prediction - y_data).flatten()})\n",
    "\n",
    "print (prediction_data)\n",
    "\n",
    "_ = sns.lmplot(y='MCMC', x='actual', data=prediction_data,\n",
    "               line_kws={'color': 'red', 'alpha': 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 15))\n",
    "\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.plot(y_data, 'ks', alpha=0.5, label='(x, y)') # full data (train+test)\n",
    "ax1.plot(posterior_preds['out'][0] ,'r', lw=2, alpha=0.5, label='posterior predictive draws')\n",
    "ax1.plot(posterior_preds['out'][1:5].reshape(4,X_data.shape[0]).T, 'r', lw=2, alpha=0.5)\n",
    "ax1.legend()\n",
    "\n",
    "ax2 = fig.add_subplot(212)\n",
    "ax2.plot(y_data, 'ks', alpha=0.5, label='(x, y)') # full data (train+test)\n",
    "ax2.plot(mean_prediction , 'r', lw=2, alpha=0.5, label='mean')\n",
    "ax2.fill_between( np.arange(len(y_data)), (mean_prediction-2*stddev_prediction).ravel(), (mean_prediction+2*stddev_prediction).ravel(), alpha = 0.3, color = 'orange',label='uncertanity')\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE = np.sqrt(np.mean(prediction_data.error_MCMC ** 2))\n",
    "\n",
    "print(f'RMSE for MCMC predictions = {RMSE:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(trace.get_values('w_in_1').shape)\n",
    "\n",
    "param_samples_MCMC = pd.DataFrame(\n",
    "    {'w_in_1[0,0]': trace.get_values('w_in_1').reshape(trace.get_values('w_in_1').shape[0],trace.get_values('w_in_1').shape[2])[:,0], \n",
    "     'w_in_1[0,1]': trace.get_values('w_in_1').reshape(trace.get_values('w_in_1').shape[0],trace.get_values('w_in_1').shape[2])[:,1]})\n",
    "\n",
    "_ = sns.scatterplot(x='w_in_1[0,0]', y='w_in_1[0,1]', data=param_samples_MCMC).set_title('MCMC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (trace['w_in_1'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
