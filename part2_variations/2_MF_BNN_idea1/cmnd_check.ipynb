{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named 'mkl'\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import theano\n",
    "floatX = theano.config.floatX\n",
    "import pymc3 as pm\n",
    "import theano.tensor as T\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "sns.set_style('white')\n",
    "np.random.seed(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.66772841]\n",
      " [-2.46244005]]\n",
      "[[-2.11939794 -2.51323535]\n",
      " [-4.01385615 -2.80462661]]\n",
      "[[-2.11939794]\n",
      " [-4.01385615]]\n",
      "[[-2.51323535]\n",
      " [-2.80462661]]\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 10\n",
    "\n",
    "# Initialize random weights between each layer\n",
    "weights_in_1 = np.random.randn(1, n_hidden).astype(floatX)\n",
    "weights_1_2 = np.random.randn(n_hidden, n_hidden).astype(floatX)\n",
    "weights_2_out = np.random.randn(n_hidden,2).astype(floatX)\n",
    "\n",
    "bias_in_1 = np.random.randn(n_hidden).astype(floatX)\n",
    "bias_1_2 = np.random.randn(n_hidden).astype(floatX)\n",
    "bias_2_out = np.random.randn(2).astype(floatX)\n",
    "\n",
    "\n",
    "def DNN(x_tensor, weights_in_1, bias_in_1, weights_1_2, bias_1_2, weights_2_out, bias_2_out):\n",
    "    act_1 = pm.math.tanh(pm.math.dot(x_tensor,weights_in_1)+bias_in_1)\n",
    "    act_2 = pm.math.tanh(pm.math.dot(act_1,weights_1_2)+bias_1_2)\n",
    "    act_out = pm.math.dot(act_2,weights_2_out)+bias_2_out\n",
    "    return act_out\n",
    "\n",
    "\n",
    "x_tensor = np.random.randn(2,1)\n",
    "print (x_tensor) \n",
    "t = DNN(x_tensor, weights_in_1, bias_in_1, weights_1_2, bias_1_2, weights_2_out, bias_2_out).eval()\n",
    "print (t)\n",
    "print (t[:,0][:,None])\n",
    "print (t[:,1][:,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.81085375 0.3553279 ]\n"
     ]
    }
   ],
   "source": [
    "print (t[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_l = 50,12 # number of low fidelity data observations\n",
    "N_h = 13,5 # number of high fidelity data observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.55590085]\n",
      " [-1.86220091]]\n",
      "[[-0.09105339  2.98473423  0.98569698  0.83642283]\n",
      " [ 1.2159812  -4.88129871 -0.50876703 -2.28190528]]\n",
      "[[[-0.09105339  2.98473423]]\n",
      "\n",
      " [[ 1.2159812  -4.88129871]]] (2, 2)\n",
      "[[[ 0.98569698  0.83642283]]\n",
      "\n",
      " [[-0.50876703 -2.28190528]]]\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 10\n",
    "\n",
    "# Initialize random weights between each layer\n",
    "weights_in_1 = np.random.randn(1, n_hidden).astype(floatX)\n",
    "weights_1_2 = np.random.randn(n_hidden, n_hidden).astype(floatX)\n",
    "weights_2_out = np.random.randn(n_hidden,4).astype(floatX)\n",
    "\n",
    "bias_in_1 = np.random.randn(n_hidden).astype(floatX)\n",
    "bias_1_2 = np.random.randn(n_hidden).astype(floatX)\n",
    "bias_2_out = np.random.randn(4).astype(floatX)\n",
    "\n",
    "\n",
    "def DNN(x_tensor, weights_in_1, bias_in_1, weights_1_2, bias_1_2, weights_2_out, bias_2_out):\n",
    "    act_1 = pm.math.tanh(pm.math.dot(x_tensor,weights_in_1)+bias_in_1)\n",
    "    act_2 = pm.math.tanh(pm.math.dot(act_1,weights_1_2)+bias_1_2)\n",
    "    act_out = pm.math.dot(act_2,weights_2_out)+bias_2_out\n",
    "    return act_out\n",
    "\n",
    "\n",
    "x_tensor = np.random.randn(2,1)\n",
    "print (x_tensor) \n",
    "t = DNN(x_tensor, weights_in_1, bias_in_1, weights_1_2, bias_1_2, weights_2_out, bias_2_out).eval()\n",
    "print (t)\n",
    "print (t[:,:2][:,None], t[:,:2].shape)\n",
    "print (t[:,-2:][:,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.10989906]\n",
      " [0.70776029]]\n",
      "[[2.11166689 3.09742941]\n",
      " [0.01024066 0.81388516]]\n",
      "[2.11166689 0.01024066]\n",
      "[3.09742941 0.81388516]\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 10\n",
    "\n",
    "# Initialize random weights between each layer\n",
    "weights_in_1 = np.random.randn(1, n_hidden).astype(floatX)\n",
    "weights_1_2 = np.random.randn(n_hidden, n_hidden).astype(floatX)\n",
    "weights_2_out = np.random.randn(n_hidden,2).astype(floatX)\n",
    "\n",
    "bias_in_1 = np.random.randn(n_hidden).astype(floatX)\n",
    "bias_1_2 = np.random.randn(n_hidden).astype(floatX)\n",
    "bias_2_out = np.random.randn(2).astype(floatX)\n",
    "\n",
    "\n",
    "def DNN(x_tensor, weights_in_1, bias_in_1, weights_1_2, bias_1_2, weights_2_out, bias_2_out):\n",
    "    act_1 = pm.math.tanh(pm.math.dot(x_tensor,weights_in_1)+bias_in_1)\n",
    "    act_2 = pm.math.tanh(pm.math.dot(act_1,weights_1_2)+bias_1_2)\n",
    "    act_out = pm.math.dot(act_2,weights_2_out)+bias_2_out\n",
    "    return act_out\n",
    "\n",
    "\n",
    "x_tensor = np.random.randn(2,1)\n",
    "print (x_tensor) \n",
    "t = DNN(x_tensor, weights_in_1, bias_in_1, weights_1_2, bias_1_2, weights_2_out, bias_2_out).eval()\n",
    "print (t)\n",
    "print (t[:,0])\n",
    "print (t[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
